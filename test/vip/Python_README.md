# Coherency framework

The purpose of the Python framework is the following:
- Generate a coherent, randomized initial state for caches and main memory
- Generate randomized cache transaction
- Reconstruct the state of caches and main memory after simulation
- Run a coherency check

The file `cache_coherency_test.py` contains a command line interface for generating the initial states and running the coherency check. The CLI is replicated in the Makefile of this repository. See the README of this repository for instructions how to run it.

## Components

The main class is `CacheCoherencyTest`. The example tests included, `RandomTest` and `ConflictTest`, extend this class. It provides functions to either generate a randomized initial state and transactions, or define them manually. It also contains methods for running coherency check.

`CacheCoherencyTest` includes the following key components:
- `caches` - a list of `CacheState` elements
- `mem_state` - a `MemoryState` element
- `transactions` - a list of `CacheTransactionSequence` elements
- `mem_ranges` - a list of `MemoryRange` elements

## Principle

The operating principle of the Python flow is as follows:
1. Generate the initial state
1. Run a coherency check on the initial state
1. Generate the transactions
1. (run the RTL simulation)
1. Start to reconstruct state from the logfiles generated by SystemVerilog
1. After each change, run the coherency check
1. Check from logfile whether the check was succesful

## Coherency check
By default, the coherency check is run at two occasions:
- After generating the initial state
- During state reconstruction - here the check is run after each change in cache to detect the exact timestamp when coherency was lost.

The check checks for the following conditions:
- A modified (i.e. different from main memory) cache line must not be in Exclusive state
- A modified cache line must be in either Owned or Modified state in one of the caches
- Cache line states must be compatible (e.g. one cache line in both Modified and Shared states is not allowed)

The checking is implementing in a very robust way (all cache entries are checked each timestamp), so, unless someone implements a more optimized algorithm, for larger cache sizes the check can take an unbearably long time. Thus, it is recommended to keep the memory and cache sizes around the same size as what is provided by default. It also makes sense because smaller cache and memory sizes generate more snoop traffic.
